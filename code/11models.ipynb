{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这个文件做了什么\n",
    "\n",
    "- XGBoost 11模型处理数据不平衡（为啥是11，因为正负样本比是1:11）\n",
    "- LightGBM 11模型，获得最优结果0.772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "import gc\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def data_prepare(num=None):\n",
    "    train = pd.read_csv('../data/handled/train.csv', nrows=num, index_col=0)\n",
    "    test = pd.read_csv('../data/handled/test.csv', nrows=num, index_col=0)\n",
    "    y_train = pd.read_csv('../data/handled/y_train.csv', nrows=num, header=-1, index_col=0)\n",
    "    return train, test, y_train\n",
    "\n",
    "\n",
    "def output_result(test_id, test_prob, sid=''):\n",
    "    result = pd.DataFrame(np.column_stack((test_id, test_prob)))\n",
    "    result.columns = ['SK_ID_CURR', 'TARGET']\n",
    "    result['SK_ID_CURR'] = result['SK_ID_CURR'].astype('int')\n",
    "    result.to_csv('./submission/submission_' + str(sid) + '.csv', header=True, index=False)\n",
    "\n",
    "\n",
    "def show_importance(model, num=20, height=0.8):\n",
    "    xgb.plot_importance(model, max_num_features=num, height=height)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def xgb_k_folder_cv(params, xgtrain, fold=5, seed=918):\n",
    "    cv = xgb.cv(params, xgtrain, metrics='auc', early_stopping_rounds=50,\n",
    "                nfold=fold, seed=seed)\n",
    "    return cv   # ['test-auc-mean'].values[-1]\n",
    "\n",
    "\n",
    "def xgb_evaluate(params,\n",
    "                 xgtrain,\n",
    "                 #   以下需要再次调用匿名函数封装\n",
    "                 eta,\n",
    "                 min_child_weight,\n",
    "                 cosample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "    params['eta'] = max(eta, 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(cosample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "    cv = xgb.cv(params, xgtrain, metrics='auc', early_stopping_rounds=50,\n",
    "                nfold=5, seed=918)\n",
    "    return cv['test-auc-mean'].values[-1]\n",
    "\n",
    "\n",
    "def xgb_no_feature_select(train: pd.DataFrame, test: pd.DataFrame, y_train, cv=False):\n",
    "    params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': 918,\n",
    "        'alpha': 9.6523,\n",
    "        'cosample_bytree': 0.9604,\n",
    "        'eta': 0.1171,\n",
    "        'gamma': 0.179,\n",
    "        'max_depth': 7,\n",
    "        'min_child_weight': 13,\n",
    "        'subsample': 0.9609\n",
    "    }\n",
    "    xgtrain = xgb.DMatrix(train, label=y_train)\n",
    "    if cv:\n",
    "        cv_res = xgb_k_folder_cv(params, xgtrain)\n",
    "        print(cv_res)\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(train, y_train)\n",
    "    y_predict = model.predict_proba(test)\n",
    "    return model, y_predict\n",
    "\n",
    "\n",
    "def xgb_feature_select(train, test, y_train, importance, top_num=None, cv=False):\n",
    "    if top_num:\n",
    "        threshold = np.sort(importance)[-top_num-1]\n",
    "    else:\n",
    "        threshold = 0\n",
    "    select_id = [True if i > threshold else False for i in importance]\n",
    "    train = train.loc[:, select_id]\n",
    "    test = test.loc[:, select_id]\n",
    "    params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': 918,\n",
    "        'alpha': 9.6523,\n",
    "        'cosample_bytree': 0.9604,\n",
    "        'eta': 0.1171,\n",
    "        'gamma': 0.179,\n",
    "        'max_depth': 7,\n",
    "        'min_child_weight': 13,\n",
    "        'subsample': 0.9609\n",
    "    }\n",
    "    xgtrain = xgb.DMatrix(train, label=y_train)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "    if cv:\n",
    "        cv_res = xgb_k_folder_cv(params, xgtrain)\n",
    "        print(cv_res)\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(train, y_train)\n",
    "    y_predict = model.predict_proba(test)\n",
    "    return model, y_predict\n",
    "\n",
    "\n",
    "def xgb_bayes_opt(train, y_train):\n",
    "    # num_rounds = 3000\n",
    "    random_state = 918\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state,\n",
    "    }\n",
    "    xgtrian = xgb.DMatrix(train, label=y_train)\n",
    "    _xgb_evaluate = lambda a, b, c, d, e, f, g: xgb_evaluate(params, xgtrian, a, b, c, d, e, f, g)\n",
    "    xgbBO = BayesianOptimization(_xgb_evaluate, {\n",
    "        'eta': (0.1, 0.5),\n",
    "        'min_child_weight': (1, 20),\n",
    "        'cosample_bytree': (0.1, 1),\n",
    "        'max_depth': (5, 15),\n",
    "        'subsample': (0.5, 1),\n",
    "        'gamma': (0, 10),\n",
    "        'alpha': (0, 10)\n",
    "    })\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    return xgbBO\n",
    "\n",
    "\n",
    "def xgb_unbalance_handle(train, test):\n",
    "    pass\n",
    "\n",
    "\n",
    "def models_stack(trian, test):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train  = data_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Imputer()\n",
    "train = im.fit_transform(df_train.values)\n",
    "test = im.transform(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(df_train.shape[0])\n",
    "np.random.seed(918)\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "idx_list = []\n",
    "num = df_train.shape[0] // 11\n",
    "for i in range(11):\n",
    "    if i != 0:\n",
    "        idx_list.append(idxs[i * num:(i+1) * num])\n",
    "    else:\n",
    "        idx_list.append(idxs[10 * num: ])\n",
    "\n",
    "length = 0\n",
    "for i in idx_list:\n",
    "    length += len(i)\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': 918,\n",
    "        'alpha': 9.6523,\n",
    "        'cosample_bytree': 0.9604,\n",
    "        'eta': 0.1171,\n",
    "        'gamma': 0.179,\n",
    "        'max_depth': 7,\n",
    "        'min_child_weight': 13,\n",
    "        'subsample': 0.9609\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_list = [XGBClassifier(**params) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "for i, idx in enumerate(idx_list):\n",
    "    new_train = train[idx, :]\n",
    "    new_y_train = y_train.values[idx]\n",
    "    cls_list[i].fit(new_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "for cls in cls_list:\n",
    "    predict_list.append(cls.predict_proba(test)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.mean(np.array(predict_list), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result(df_test.index, res, sid='_11models_mean')  # 0.769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    'nthread': 4,\n",
    "    #is_unbalance=True,\n",
    "    'n_estimators' : 10000,\n",
    "    'learning_rate' : 0.1171,\n",
    "    #'num_leaves' : 32,\n",
    "    'colsample_bytree' : 0.9604,\n",
    "    'subsample' : 0.9609,\n",
    "    'max_depth' : 7,\n",
    "    'reg_alpha' : 9.6523,\n",
    "    'reg_lambda' : 1,\n",
    "    'min_split_gain' : 0.179,\n",
    "    'min_child_weight' : 13,\n",
    "    'metric': 'auc',\n",
    "    'silent': -1,\n",
    "    'verbose': -1,\n",
    "    #scale_pos_weight=11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(**params_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:394: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/usr/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:661: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc-mean': [0.709094446889912,\n",
       "  0.7166094169418263,\n",
       "  0.7200212031463803,\n",
       "  0.723998477597493,\n",
       "  0.7272192375196305,\n",
       "  0.7292442359058453,\n",
       "  0.7321313463225254,\n",
       "  0.7343587797677004,\n",
       "  0.736540781308255,\n",
       "  0.7386130375435341,\n",
       "  0.7406999834370118,\n",
       "  0.7422023446570056,\n",
       "  0.744160993789141,\n",
       "  0.7457347829907458,\n",
       "  0.7469706972597552,\n",
       "  0.7489137982776963,\n",
       "  0.7502076508807051,\n",
       "  0.751499659917497,\n",
       "  0.752744465126623,\n",
       "  0.7539589416303054,\n",
       "  0.7551041135587486,\n",
       "  0.7560605269835544,\n",
       "  0.7569793442113315,\n",
       "  0.757837913523469,\n",
       "  0.758697630905913,\n",
       "  0.7593878533176487,\n",
       "  0.7601775242526669,\n",
       "  0.7607420993914591,\n",
       "  0.7615622586615319,\n",
       "  0.7621683750204936,\n",
       "  0.7627208560159296,\n",
       "  0.7632610123146928,\n",
       "  0.7637425534514876,\n",
       "  0.764109089804606,\n",
       "  0.7646056938879124,\n",
       "  0.7649797515261294,\n",
       "  0.7655595282570864,\n",
       "  0.7658867011224862,\n",
       "  0.766130505408092,\n",
       "  0.7664208763825641,\n",
       "  0.7668262267757617,\n",
       "  0.7671115924866918,\n",
       "  0.767338052290021,\n",
       "  0.7676093329841817,\n",
       "  0.7679317914012883,\n",
       "  0.7682163136491438,\n",
       "  0.7683861748194426,\n",
       "  0.7686600876751435,\n",
       "  0.7689282246873551,\n",
       "  0.7691546343718336,\n",
       "  0.7693664740087016,\n",
       "  0.7695905970771794,\n",
       "  0.7697624116996894,\n",
       "  0.7699643363024979,\n",
       "  0.7702114565060935,\n",
       "  0.7703939873080351,\n",
       "  0.7705847270572667,\n",
       "  0.7707458953714553,\n",
       "  0.7709291336372377,\n",
       "  0.7710780496930385,\n",
       "  0.7712447904761953,\n",
       "  0.7713740487119283,\n",
       "  0.7715279007042957,\n",
       "  0.77173426932835,\n",
       "  0.771860139123163,\n",
       "  0.7720154445733309,\n",
       "  0.7721924206446816,\n",
       "  0.7723050169092074,\n",
       "  0.7724425788693864,\n",
       "  0.7725901956932751,\n",
       "  0.7726632284529054,\n",
       "  0.7727545894438677,\n",
       "  0.7728652886114202,\n",
       "  0.7729499414330194,\n",
       "  0.7730348595660557,\n",
       "  0.7731035114641317,\n",
       "  0.7732055436138359,\n",
       "  0.7733100119862655,\n",
       "  0.7733967192776012,\n",
       "  0.7734260946031367,\n",
       "  0.773489992218326,\n",
       "  0.7735411330996078,\n",
       "  0.7735752776208652,\n",
       "  0.7736164325152309,\n",
       "  0.7737506366754705,\n",
       "  0.7737952522457627,\n",
       "  0.7738690326197931,\n",
       "  0.7739831390476721,\n",
       "  0.7741495633635697,\n",
       "  0.7742975464229958,\n",
       "  0.7743500605260825,\n",
       "  0.7743781145872507,\n",
       "  0.7744247419562985,\n",
       "  0.7744773001280635,\n",
       "  0.7745653459776497,\n",
       "  0.7745921667990189,\n",
       "  0.7746356218154639,\n",
       "  0.7747207748406275,\n",
       "  0.7747559632941322,\n",
       "  0.774826204233983,\n",
       "  0.7749257342661788,\n",
       "  0.7749498990706617,\n",
       "  0.775025571259427,\n",
       "  0.7750653154023107,\n",
       "  0.7750612602928648,\n",
       "  0.7750761542124517,\n",
       "  0.775127511191695,\n",
       "  0.7751850420115559,\n",
       "  0.7752617398430216,\n",
       "  0.7753012158673818,\n",
       "  0.7752854827507082,\n",
       "  0.7753168645675672,\n",
       "  0.7753528207689933,\n",
       "  0.7753821513843191,\n",
       "  0.7754824849677918,\n",
       "  0.7754858374501313,\n",
       "  0.7755220694003047,\n",
       "  0.7755346003979577,\n",
       "  0.7755705517326634,\n",
       "  0.7755979961153018,\n",
       "  0.7756726565461365,\n",
       "  0.7757065532925282,\n",
       "  0.7757124136472908,\n",
       "  0.7757449889088709,\n",
       "  0.7757585815796242,\n",
       "  0.7758206315928571,\n",
       "  0.775853911660797,\n",
       "  0.7758674366330387,\n",
       "  0.7758768796585132,\n",
       "  0.7758942879165538,\n",
       "  0.7759249287938956,\n",
       "  0.7759169267909942,\n",
       "  0.7759192997549993,\n",
       "  0.7759111945260477,\n",
       "  0.7759313176928975,\n",
       "  0.775932757824655,\n",
       "  0.7759476005078119,\n",
       "  0.775968470669138,\n",
       "  0.775975181430053,\n",
       "  0.7759696202200159,\n",
       "  0.775977809344589,\n",
       "  0.7759747714782613,\n",
       "  0.7759864437385283,\n",
       "  0.7759891903636097],\n",
       " 'auc-stdv': [0.0024829815332778208,\n",
       "  0.0016016860637824636,\n",
       "  0.001750927756857139,\n",
       "  0.0014991449469055002,\n",
       "  0.001451876032462472,\n",
       "  0.0010966530414058227,\n",
       "  0.0018715371098537003,\n",
       "  0.0020323925530476676,\n",
       "  0.0024916116131769275,\n",
       "  0.0024170608169028183,\n",
       "  0.0018597659983572348,\n",
       "  0.002104600129203619,\n",
       "  0.001647092385883573,\n",
       "  0.0016756511080889274,\n",
       "  0.0018687157455368436,\n",
       "  0.0017421528565068289,\n",
       "  0.002091171846313422,\n",
       "  0.0022079776802514045,\n",
       "  0.002239547209914979,\n",
       "  0.0020467768728408223,\n",
       "  0.0021218007508631916,\n",
       "  0.0022024767898064838,\n",
       "  0.002387170386511163,\n",
       "  0.0022953207907163964,\n",
       "  0.0024142920084788324,\n",
       "  0.0022822801929616664,\n",
       "  0.002384858161641495,\n",
       "  0.002318572240965463,\n",
       "  0.0023668380056926144,\n",
       "  0.0022645537000207023,\n",
       "  0.0023329204027570404,\n",
       "  0.0021847832155789323,\n",
       "  0.002252709007092718,\n",
       "  0.00221148147581725,\n",
       "  0.0023081210890824786,\n",
       "  0.002321675213135999,\n",
       "  0.0021375825994538623,\n",
       "  0.002089737137437297,\n",
       "  0.002107488967185103,\n",
       "  0.0021005406986881713,\n",
       "  0.0020794752145259863,\n",
       "  0.00212442655816594,\n",
       "  0.002125682164582602,\n",
       "  0.0022034951215051455,\n",
       "  0.0022104095059547633,\n",
       "  0.0022931008417506867,\n",
       "  0.0023107676726526116,\n",
       "  0.002305271694105527,\n",
       "  0.002133459102049047,\n",
       "  0.002118924230944015,\n",
       "  0.0020932739662563593,\n",
       "  0.0020871105765467935,\n",
       "  0.0021494509100798255,\n",
       "  0.0021406977837713855,\n",
       "  0.0020736335500369527,\n",
       "  0.0020688730875418303,\n",
       "  0.0021055551555955758,\n",
       "  0.002191874070698499,\n",
       "  0.002237523485821338,\n",
       "  0.0022521539303051188,\n",
       "  0.0022283729089112685,\n",
       "  0.002236989194976481,\n",
       "  0.0022398819922394898,\n",
       "  0.002235491089374164,\n",
       "  0.0022931889390325794,\n",
       "  0.002318207235565458,\n",
       "  0.0024311066543305604,\n",
       "  0.0024437223352562053,\n",
       "  0.0024235375717373887,\n",
       "  0.002419048952211863,\n",
       "  0.0024382554257965892,\n",
       "  0.0024138395455778777,\n",
       "  0.002411156534787659,\n",
       "  0.0023997015325894168,\n",
       "  0.002390236106224109,\n",
       "  0.0023825230360333873,\n",
       "  0.002392876631685624,\n",
       "  0.0023634084697276223,\n",
       "  0.0023291566069966927,\n",
       "  0.002350486203552138,\n",
       "  0.0023475255338594988,\n",
       "  0.002349243078604281,\n",
       "  0.0023238510106503686,\n",
       "  0.0023640889607835576,\n",
       "  0.002360087632009215,\n",
       "  0.002339108437828196,\n",
       "  0.002316912937795388,\n",
       "  0.002290400691607998,\n",
       "  0.0022329098037293022,\n",
       "  0.002304773025142003,\n",
       "  0.0023670990314584254,\n",
       "  0.002361159691666012,\n",
       "  0.002329851605926889,\n",
       "  0.002350068336497259,\n",
       "  0.002309890792143745,\n",
       "  0.0023269621704783815,\n",
       "  0.002350371105885289,\n",
       "  0.0023776662447753264,\n",
       "  0.0024171060685692553,\n",
       "  0.0024133915303357575,\n",
       "  0.002379142173983842,\n",
       "  0.0023805569643543635,\n",
       "  0.002401594183815074,\n",
       "  0.0023484123210449335,\n",
       "  0.002342965947726049,\n",
       "  0.002363886278061245,\n",
       "  0.0023784247270081603,\n",
       "  0.002406913026073823,\n",
       "  0.0024084880488549217,\n",
       "  0.002434713185735504,\n",
       "  0.0024568754738217196,\n",
       "  0.0025163369384609835,\n",
       "  0.0025107092435369747,\n",
       "  0.002517899521114064,\n",
       "  0.0025626815473951425,\n",
       "  0.002589531498978947,\n",
       "  0.002599627018088201,\n",
       "  0.0025863204958263527,\n",
       "  0.0025865240850939885,\n",
       "  0.0026395204924147962,\n",
       "  0.002691618783472997,\n",
       "  0.0027087643278564913,\n",
       "  0.0026776588271470755,\n",
       "  0.0026927984601093874,\n",
       "  0.00268094611842709,\n",
       "  0.0026723137402065128,\n",
       "  0.0027022959830947674,\n",
       "  0.002710891647972002,\n",
       "  0.0027551101970781974,\n",
       "  0.002747487181877249,\n",
       "  0.0027558042176047555,\n",
       "  0.002732489516694641,\n",
       "  0.002711059547234238,\n",
       "  0.0027075156661452203,\n",
       "  0.0027122577391691487,\n",
       "  0.002718560070471141,\n",
       "  0.002705035075893062,\n",
       "  0.0027143012804684433,\n",
       "  0.0027409846513433474,\n",
       "  0.002735388758100121,\n",
       "  0.0027326585266265403,\n",
       "  0.002706672445507933,\n",
       "  0.002694637605227726,\n",
       "  0.002698115347330739]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgtrain = lgb.Dataset(train, label=y_train.values.ravel())\n",
    "lgb.cv(params_lgb, xgtrain, 10, nfold=5, metrics='auc', early_stopping_rounds=10,\n",
    "       # This is what I added\n",
    "        stratified=False)\n",
    "\n",
    "\n",
    "#model = lgb.LGBMClassifier(**params)\n",
    "#model.fit(train, y_train)\n",
    "#y_predict = model.predict_proba(test)\n",
    "#return model, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_list = [lgb.LGBMClassifier(**params_lgb) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "for i, idx in enumerate(idx_list):\n",
    "    new_train = train[idx, :]\n",
    "    new_y_train = y_train.values[idx]\n",
    "    cls_list[i].fit(new_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "for cls in cls_list:\n",
    "    predict_list.append(cls.predict_proba(test)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.mean(np.array(predict_list), axis=0)\n",
    "\n",
    "output_result(df_test.index, res, sid='11models_mean_lgb')  # 0.772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 RobusxtScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.705973       0.001680       0.700744      0.004082\n",
      "1        0.714776       0.002003       0.708041      0.005586\n",
      "2        0.721093       0.001433       0.712055      0.005532\n",
      "3        0.729924       0.001927       0.719409      0.005051\n",
      "4        0.733852       0.002252       0.722567      0.004702\n",
      "5        0.738533       0.001697       0.726365      0.004990\n",
      "6        0.742360       0.001394       0.729371      0.005238\n",
      "7        0.745623       0.001581       0.731764      0.005240\n",
      "8        0.749460       0.001838       0.734793      0.005099\n",
      "9        0.752700       0.001473       0.737192      0.005509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(alpha=9.6523, base_score=0.5, booster='gbtree',\n",
       "        colsample_bylevel=1, colsample_bytree=1, cosample_bytree=0.9604,\n",
       "        eta=0.1171, eval_metric='auc', gamma=0.179, learning_rate=0.1,\n",
       "        max_delta_step=0, max_depth=7, min_child_weight=13, missing=None,\n",
       "        n_estimators=100, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=918, silent=1, subsample=0.9609, verbose_eval=True),\n",
       " array([[0.9400627 , 0.05993729],\n",
       "        [0.8798291 , 0.12017091],\n",
       "        [0.9652743 , 0.03472573],\n",
       "        ...,\n",
       "        [0.9862132 , 0.01378676],\n",
       "        [0.9527332 , 0.04726679],\n",
       "        [0.8011434 , 0.19885659]], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_no_feature_select(train, test, y_train, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = rs.fit_transform(train, y_train)\n",
    "test2 = rs.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.705973       0.001680       0.700744      0.004082\n",
      "1        0.714776       0.002003       0.708041      0.005586\n",
      "2        0.721093       0.001433       0.712055      0.005532\n",
      "3        0.729924       0.001927       0.719408      0.005051\n",
      "4        0.733852       0.002252       0.722566      0.004702\n",
      "5        0.738533       0.001697       0.726364      0.004990\n",
      "6        0.742360       0.001394       0.729370      0.005237\n",
      "7        0.745623       0.001581       0.731763      0.005240\n",
      "8        0.749460       0.001838       0.734792      0.005098\n",
      "9        0.752701       0.001473       0.737192      0.005509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(alpha=9.6523, base_score=0.5, booster='gbtree',\n",
       "        colsample_bylevel=1, colsample_bytree=1, cosample_bytree=0.9604,\n",
       "        eta=0.1171, eval_metric='auc', gamma=0.179, learning_rate=0.1,\n",
       "        max_delta_step=0, max_depth=7, min_child_weight=13, missing=None,\n",
       "        n_estimators=100, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=918, silent=1, subsample=0.9609, verbose_eval=True),\n",
       " array([[0.9540579 , 0.04594211],\n",
       "        [0.88835865, 0.11164133],\n",
       "        [0.96245784, 0.03754215],\n",
       "        ...,\n",
       "        [0.9888067 , 0.01119326],\n",
       "        [0.96069896, 0.03930106],\n",
       "        [0.79613644, 0.20386358]], dtype=float32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_no_feature_select(train2, test2, y_train, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64019574, 0.63121106, 0.64117802, 0.64215522, 0.6330202 ,\n",
       "       0.6299061 , 0.63554476, 0.63466676, 0.6340634 , 0.64615358])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "gnb = RandomForestClassifier()\n",
    "cross_val_score(gnb, X=train, y=y_train, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_result(n_estimators, \n",
    "                  max_depth, \n",
    "                  min_samples_split, \n",
    "                  min_samples_leaf, \n",
    "                  max_leaf_nodes,\n",
    "                 ):\n",
    "    rf = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "                                max_depth = max(0, int(max_depth)),\n",
    "                                min_samples_split = max(0, int(min_samples_split)),\n",
    "                                min_samples_leaf = max(0, int(min_samples_leaf)),\n",
    "                                max_leaf_nodes = max(0, int(max_leaf_nodes))\n",
    "                               )\n",
    "    return np.mean(cross_val_score(rf, train, y_train, cv=10, scoring='roc_auc'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfBO = BayesianOptimization(get_rf_result,\n",
    "        {'n_estimators': (10, 500), \n",
    "         'max_depth': (5, 20),\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
