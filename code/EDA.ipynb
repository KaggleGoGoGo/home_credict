{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/application_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_train.iloc[:, 2:]\n",
    "df_y = df_train['TARGET']\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureByMissing = df_x_train.columns[df_x_train.isnull().sum()/df_x_train.shape[0] < 0.3]\n",
    "df_x_train = df_x_train[FeatureByMissing]\n",
    "df_x_test = df_x_test[FeatureByMissing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.get_dummies(df_x_train) \n",
    "# 先用pandas自带的独热编码进行编码，然后再填补缺失值\n",
    "# 缺点：多分类变量有可能几个虚拟变量都为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainColumn = df_x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_x_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常值\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值\n",
    "imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imputer.fit(x_train)\n",
    "x_train = imputer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化\n",
    "ss = StandardScaler()\n",
    "ss.fit(x_train)\n",
    "x_train = ss.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandle:\n",
    "    def __init__(self, missing_rate=0.3):\n",
    "        self.missing_rate = missing_rate\n",
    "        self.clear()\n",
    "    \n",
    "    def clear(self):\n",
    "        self.imputer = None\n",
    "        self.ss = None\n",
    "        self.sfm = None\n",
    "        self.x_before = None\n",
    "        self.x_after = None\n",
    "        self.feature_by_missing = None\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.clear()\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError\n",
    "        self.x_before = x\n",
    "        self.y_before = y\n",
    "        self.y_after = y\n",
    "        self.feature_by_missing = x.columns[x.isnull().sum()/x.shape[0] < self.missing_rate]\n",
    "        self.x_before = self.x_before[self.feature_by_missing]\n",
    "        self.x_before = pd.get_dummies(self.x_before)\n",
    "        self.x_after = self.data_preprocess(self.x_before.values, y)\n",
    "        \n",
    "    def data_preprocess(self, x, y=None):\n",
    "        assert isinstance(x, np.ndarray)\n",
    "        # 异常值\n",
    "        pass\n",
    "\n",
    "        # 缺失值\n",
    "        if self.imputer is None:\n",
    "            self.imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "            self.imputer.fit(x)\n",
    "        x =  self.imputer.transform(x)\n",
    "\n",
    "        # 标准化\n",
    "        if self.ss is None:\n",
    "            self.ss = StandardScaler()\n",
    "            self.ss.fit(x)\n",
    "        x = self.ss.transform(x)\n",
    "\n",
    "        # 特征选择\n",
    "        if self.sfm is None:\n",
    "            self.sfm = SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.01))\n",
    "            self.sfm.fit(x, y)\n",
    "        x = self.sfm.transform(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def transform(self, x_test):\n",
    "        x_test = x_test[self.feature_by_missing]\n",
    "        x_test = pd.get_dummies(x_test)\n",
    "        # 统一train和test的特征\n",
    "        _, x_test = self.x_before.align(x_test, join='left', axis=1, fill_value=0)\n",
    "        x_test = self.data_preprocess(x_test.values)\n",
    "        return self.x_after, self.y_after, x_test\n",
    "\n",
    "\n",
    "def get_auc_score(y_true, y_predict_proba):\n",
    "    f, t, _ = roc_curve(y_true, y_predict_proba, pos_label=1)\n",
    "    return auc(f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHandle()\n",
    "dh.fit(df_x_train, df_y_train)\n",
    "x_train, y_train, x_test = dh.transform(df_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396479831646039"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_score(df_y_test, lr.predict_proba(x_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/application_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:, 2:]\n",
    "y_train = df_train['TARGET'].values\n",
    "\n",
    "x_test = df_test.iloc[:, 1:]\n",
    "test_id  = df_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dh = DataHandle()\n",
    "#dh.fit(x_train, y_train)\n",
    "x_train, y_train, x_test = dh.transform(x_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_predict_prob = lr.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.column_stack((test_id, y_predict_prob[:, 1])))\n",
    "result.columns = ['SK_ID_CURR', 'TARGET']\n",
    "result['SK_ID_CURR'] = result['SK_ID_CURR'].astype('int')\n",
    "result.to_csv('submission.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
