{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data/application_train.csv\")\n",
    "df_test = pd.read_csv(\"../../data/application_test.csv\")\n",
    "TARGET = df_train['TARGET']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_test.iloc[:, 0]\n",
    "train_id = df_train.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(x):\n",
    "    if isinstance(x[0], str):\n",
    "        return 0\n",
    "    if len( np.unique(x[:400])) < 15:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def plot(x):\n",
    "    global TARGET\n",
    "    _type = get_type(x)\n",
    "    if _type == 0:\n",
    "        discrete_plot(x, TARGET)\n",
    "    else:\n",
    "        continuous_plot(x, TARGET)\n",
    "    \n",
    "def discrete_plot(x, y):\n",
    "    temp = pd.concat((x, y), axis=1)\n",
    "    temp['value'] = 1\n",
    "    temp = temp.dropna()\n",
    "    temp.groupby(list(temp.columns)[:2]).sum().unstack().plot(kind='bar')\n",
    "    print(temp.groupby([temp.columns[0]])['TARGET'].mean())\n",
    "    print(temp.groupby([temp.columns[0]])['TARGET'].count())\n",
    "\n",
    "def continuous_plot(x, y):\n",
    "    x = x.dropna()\n",
    "    sns.distplot(x.loc[y==0])\n",
    "    sns.distplot(x.loc[y==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['TARGET']\n",
    "df_train = df_train.iloc[:, 2:]\n",
    "df_test = df_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_1_train = df_train['EXT_SOURCE_1']\n",
    "ext_1_test = df_test['EXT_SOURCE_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_by_missing = df_train.columns[df_train.isnull().sum()/df_train.shape[0] > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加 [kernel](https://www.kaggle.com/poohtls/fork-of-fork-lightgbm-with-simple-features/code) 中的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = df_train.shape[0]\n",
    "len_test = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.append(df_test).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of the continuous days variables have integers as missing value indicators.\n",
    "def mean_std(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "inc_by_org = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
    "df['NEW_CREDIT_TO_GOODS_RATIO'] = mean_std(df['AMT_CREDIT'] / df['AMT_GOODS_PRICE'])\n",
    "df['NEW_DOC_IND_KURT'] = mean_std(df[docs].kurtosis(axis=1))\n",
    "df['NEW_LIVE_IND_SUM'] = mean_std(df[live].sum(axis=1))\n",
    "df['NEW_INC_PER_CHLD'] = mean_std(df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN']))\n",
    "df['NEW_INC_BY_ORG'] = mean_std(df['ORGANIZATION_TYPE'].map(inc_by_org))\n",
    "df['NEW_EMPLOY_TO_BIRTH_RATIO'] = mean_std(df['DAYS_EMPLOYED'] / df['DAYS_BIRTH'])\n",
    "df['NEW_ANNUITY_TO_INCOME_RATIO'] = mean_std(df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL']))\n",
    "df['NEW_SOURCES_PROD'] = mean_std(df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3'])\n",
    "df['NEW_EXT_SOURCES_MEAN'] = mean_std(df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1))\n",
    "df['NEW_SCORES_STD'] = mean_std(df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1))\n",
    "df['NEW_SCORES_STD'] = mean_std(df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean()))\n",
    "df['NEW_CAR_TO_BIRTH_RATIO'] = mean_std(df['OWN_CAR_AGE'] / df['DAYS_BIRTH'])\n",
    "df['NEW_CAR_TO_EMPLOY_RATIO'] = mean_std(df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED'])\n",
    "df['NEW_PHONE_TO_BIRTH_RATIO'] = mean_std(df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH'])\n",
    "df['NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER'] = mean_std(df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED'])\n",
    "df['NEW_CREDIT_TO_INCOME_RATIO'] = mean_std(df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL'])\n",
    "df['LOAN_INCOME_RATIO'] = mean_std(df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL'])\n",
    "df['ANNUITY_INCOME_RATIO'] = mean_std(df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL'])\n",
    "\n",
    "# Number of overall payments (I think!)\n",
    "df['ANNUITY LENGTH'] = mean_std(df['AMT_CREDIT'] / df['AMT_ANNUITY'])\n",
    "\n",
    "# Social features\n",
    "df['WORKING_LIFE_RATIO'] = mean_std(df['DAYS_EMPLOYED'] / df['DAYS_BIRTH'])\n",
    "df['INCOME_PER_FAM'] = mean_std(df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS'])\n",
    "df['CHILDREN_RATIO'] = mean_std(df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcolum=['index']\n",
    "df= df.drop(dropcolum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[: len_train]\n",
    "df_test = df.iloc[len_train: , ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[i for i in df_train.columns if i not in feature_by_missing]]\n",
    "df_test = df_test[[i for i in df_train.columns if i not in feature_by_missing]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns\n",
    "drop_num  = []\n",
    "select_num = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面是对特征进行处理，跳转到最后进行特征提取并且单独测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 4] = list(map(lambda x: 5 if x >= 5 else x, df_train.iloc[:, 4])) \n",
    "df_test.iloc[:, 4] = list(map(lambda x: 5 if x >= 5 else x, df_test.iloc[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    s = 50000\n",
    "    for i in range(12):\n",
    "        if x < s + 25000 * i:\n",
    "            return str(i)\n",
    "    return '12'\n",
    "\n",
    "df_train.iloc[:, 5] = list(map(lambda x:  replace(x), df_train.iloc[:, 5]))\n",
    "df_test.iloc[:, 5] = list(map(lambda x:  replace(x), df_test.iloc[:, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    s = 600000\n",
    "    for i in range(10):\n",
    "        if x < s + 100000 * i:\n",
    "            return str(i)\n",
    "    return '10'\n",
    "\n",
    "df_train.iloc[:, 6] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_train.iloc[:, 6]))\n",
    "df_test.iloc[:, 6] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_test.iloc[:, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test.iloc[:, 7] = mean_std(np.log(df_test.iloc[:, 7]))\n",
    "df_train.iloc[:, 7] = mean_std(np.log(df_train.iloc[:, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    s = 400000\n",
    "    for i in range(4):\n",
    "        if x < s + 200000 * i:\n",
    "            return str(i)\n",
    "    return '4'\n",
    "\n",
    "df_train.iloc[:, 8] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_train.iloc[:, 8]))\n",
    "df_test.iloc[:, 8] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_test.iloc[:, 8]))\n",
    "# plot(df_train.iloc[:, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dic = {\n",
    "    'Children' : '1',\n",
    "    'Family' : '1',\n",
    "    'Spouse, partner': '1',\n",
    "    'Unaccompanied' : '0',\n",
    "    'Group of people': '2',\n",
    "    'Other_A': '2',\n",
    "    'Other_B': '2',\n",
    "}\n",
    "\n",
    "df_train.iloc[:, 9] = list(map(lambda x: map_dic[x] if not pd.isnull(x) else x, df_train.iloc[:, 9]))\n",
    "df_test.iloc[:, 9] = list(map(lambda x: map_dic[x] if not pd.isnull(x) else x, df_test.iloc[:, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dic = {\n",
    "    'Businessman':'bus_and_stu', 'Student':'bus_and_stu', \n",
    "    'Maternity leave': 'mat_and_une', 'Unemployed':'mat_and_une'\n",
    "}\n",
    "\n",
    "df_train.iloc[:, 10] = list(map(lambda x: map_dic[x] if x in map_dic else x, df_train.iloc[:, 10]))\n",
    "df_test.iloc[:, 10] = list(map(lambda x: map_dic[x] if x in map_dic else x, df_test.iloc[:, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 14] = pd.Series(list(map(lambda x: 1 if x >= 0.03 else 0 if not pd.isnull(x) else x, df_train.iloc[:, 14])))\n",
    "df_test.iloc[:, 14] = pd.Series(list(map(lambda x: 1 if x >= 0.03 else 0 if not pd.isnull(x) else x, df_test.iloc[:, 14])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重要特征！\n",
    "df_train['days_birth_dummy'] = list(map(lambda x: 1 if x > -15000 else 0 if not pd.isnull(x) else x, df_train.iloc[:, 15]))\n",
    "df_test['days_birth_dummy'] = list(map(lambda x: 1 if x > -15000 else 0 if not pd.isnull(x) else x, df_test.iloc[:, 15]))\n",
    "df_train.iloc[:, 15] = mean_std(df_train.iloc[:, 15])\n",
    "df_test.iloc[:, 15] = mean_std(df_test.iloc[:, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['days_employed_dummy'] = df_train.iloc[:, 16].map(lambda x: '2' if x>0 else '1' if x > -2100 else '0' if not pd.isnull(x) else x)\n",
    "df_test['days_employed_dummy'] = df_test.iloc[:, 16].map(lambda x: '2' if x>0 else '1' if x > -2100 else '0' if not pd.isnull(x) else x)\n",
    "\n",
    "\n",
    "df_test.iloc[:, 16] = mean_std(df_test.iloc[:, 16].map(lambda x: np.nan if x>0 else x))\n",
    "df_train.iloc[:, 16] = mean_std(df_train.iloc[:, 16].map(lambda x: np.nan if x>0 else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['days_registration_dummy'] = df_train.iloc[:, 17].map(lambda x: 1 if x> -6000 else 0 if not pd.isnull(x) else x)\n",
    "df_test['days_registration_dummy'] = df_test.iloc[:, 17].map(lambda x: 1 if x>-6000 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 17] = mean_std(df_test.iloc[:, 17])\n",
    "df_train.iloc[:, 17] = mean_std(df_train.iloc[:, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['days_idpub_dummy'] = df_train.iloc[:, 18].map(lambda x: 1 if x> -3100 else 0 if not pd.isnull(x) else x)\n",
    "df_test['days_idpub_dummy'] = df_test.iloc[:, 18].map(lambda x: 1 if x>-3100 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 18] = mean_std(df_test.iloc[:, 18])\n",
    "df_train.iloc[:, 18] = mean_std(df_train.iloc[:, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.drop(columns=columns[19])\n",
    "#df_test = df_test.drop(columns=columns[19])\n",
    "drop_num.append(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 26] = df_train.iloc[:, 26].map(lambda x: 6 if x >= 6 else x)\n",
    "df_test.iloc[:, 26] = df_test.iloc[:, 26].map(lambda x: 6 if x >= 6 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 30] = df_train.iloc[:, 30].map(lambda x: 1 if x >= 13 else 0 if not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 30] = df_test.iloc[:, 30].map(lambda x: 1 if x >= 13 else 0 if not pd.isnull(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO High-Cardinality Categorical  Cluster\n",
    "drop_num.append(35)\n",
    "# plot(df_train.iloc[:, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ext_source_2_dummy'] = df_train.iloc[:, 38].map(lambda x: 1 if x> 0.5 else 0 if not pd.isnull(x) else x)\n",
    "df_test['ext_source_2_dummy'] = df_test.iloc[:, 38].map(lambda x: 1 if x> 0.5 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 38] = mean_std(df_test.iloc[:, 38])\n",
    "df_train.iloc[:, 38] = mean_std(df_train.iloc[:, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ext_source_3_dummy'] = df_train.iloc[:, 39].map(lambda x: 1 if x> 0.42 else 0 if not pd.isnull(x) else x)\n",
    "df_test['ext_source_3_dummy'] = df_test.iloc[:, 39].map(lambda x: 1 if x> 0.42 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 39] = mean_std(df_test.iloc[:, 39])\n",
    "df_train.iloc[:, 39] = mean_std(df_train.iloc[:, 39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 40] = df_train.iloc[:, 40].map(lambda x: x if x < 5   else np.nan)\n",
    "df_test.iloc[:, 40] = df_test.iloc[:, 40].map(lambda x: x if x < 5  else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 41] = df_train.iloc[:, 41].map(lambda x: x if x <= 5 else np.nan)\n",
    "df_test.iloc[:, 41] = df_test.iloc[:, 41].map(lambda x: x if x <= 5 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 42] = df_train.iloc[:, 42].map(lambda x: x if x <= 5 else np.nan)\n",
    "df_test.iloc[:, 42] = df_test.iloc[:, 42].map(lambda x: x if x <= 5 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 43] = df_train.iloc[:, 43].map(lambda x: x if x <= 2 else 3 if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 43] = df_test.iloc[:, 43].map(lambda x: x if x <= 2 else 3 if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 44] = df_train.iloc[:, 44].map(lambda x: '0' if x < -1000 else '1' if x < 0 else '2' if not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 44] = df_test.iloc[:, 44].map(lambda x: '0' if x < -1000 else '1' if x < 0 else '2' if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(45)\n",
    "drop_num.append(47)\n",
    "drop_num.append(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 65] = df_train.iloc[:, 65].map(lambda x: '0' if x ==0 else '1' if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 65] = df_test.iloc[:, 65].map(lambda x: '0' if x ==0 else '1' if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 66] = df_train.iloc[:, 66].map(lambda x: '0' if x ==0 else '1' if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 66] = df_test.iloc[:, 66].map(lambda x: '0' if x ==0 else '1' if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 67] = df_train.iloc[:, 67].map(lambda x:  '0' if x ==0 else '1' if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 67] = df_test.iloc[:, 67].map(lambda x:  '0' if x ==0 else '1' if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 68] = df_train.iloc[:, 68].map(lambda x:  '0' if x ==0 else '1' if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 68] = df_test.iloc[:, 68].map(lambda x:  '0' if x ==0 else '1' if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 69] = df_train.iloc[:, 69].map(lambda x: 2 if x >= 2 else x)\n",
    "df_test.iloc[:, 69] = df_test.iloc[:, 69].map(lambda x: 2 if x >= 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 70] = df_train.iloc[:, 70].map(lambda x: 5 if x >= 5 else x)\n",
    "df_test.iloc[:, 70] = df_test.iloc[:, 70].map(lambda x: 5 if x >= 5 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=columns[drop_num])\n",
    "df_test = df_test.drop(columns=columns[drop_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['EXT_SOURCE_1'] = ext_1_train\n",
    "df_test['EXT_SOURCE_1'] = ext_1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcolum=['FLAG_DOCUMENT_6','FLAG_DOCUMENT_7',\n",
    "    'FLAG_DOCUMENT_8','FLAG_DOCUMENT_9', \n",
    "    'FLAG_DOCUMENT_11','FLAG_DOCUMENT_13',\n",
    "    'FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16',\n",
    "    'FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19',\n",
    "    'FLAG_DOCUMENT_20','FLAG_DOCUMENT_21']\n",
    "df_train= df_train.drop(dropcolum,axis=1)\n",
    "df_test= df_test.drop(dropcolum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.index = train_id\n",
    "df_test.index = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/handled/main_train_2.csv')\n",
    "df_test.to_csv('../data/handled/main_test_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(df_train).values\n",
    "y = TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer()\n",
    "x = imp.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(LogisticRegression(penalty='l1', C=0.2))\n",
    "x = sfm.fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74859571, 0.7474503 , 0.75273227])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "cross_val_score(lr, x, y, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dummy = pd.get_dummies(df_train, dummy_na=True)\n",
    "df_test_dummy = pd.get_dummies(df_test, dummy_na=True)\n",
    "\n",
    "train, test = df_train_dummy.align(df_test_dummy, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer()\n",
    "train = imp.fit_transform(train)\n",
    "test = imp.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(LogisticRegression(penalty='l1', C=0.3))\n",
    "train = sfm.fit_transform(train, y)\n",
    "test = sfm.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(test_id, test_prob, sid=0):\n",
    "    result = pd.DataFrame(np.column_stack((test_id, test_prob)))\n",
    "    result.columns = ['SK_ID_CURR', 'TARGET']\n",
    "    result['SK_ID_CURR'] = result['SK_ID_CURR'].astype('int')\n",
    "    result.to_csv('./submission/submission' + str(sid) + '.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = lr.predict_proba(test)\n",
    "output(test_id, pre[:, 1], '_20180707')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取、测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_test(estimator, x, y):\n",
    "    return cross_val_score(estimator, x, y, cv=5, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>NEW_CAR_TO_EMPLOY_RATIO</th>\n",
       "      <th>NEW_PHONE_TO_BIRTH_RATIO</th>\n",
       "      <th>NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER</th>\n",
       "      <th>NEW_CREDIT_TO_INCOME_RATIO</th>\n",
       "      <th>LOAN_INCOME_RATIO</th>\n",
       "      <th>ANNUITY_INCOME_RATIO</th>\n",
       "      <th>ANNUITY LENGTH</th>\n",
       "      <th>WORKING_LIFE_RATIO</th>\n",
       "      <th>INCOME_PER_FAM</th>\n",
       "      <th>CHILDREN_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.698886</td>\n",
       "      <td>-0.698886</td>\n",
       "      <td>-0.625479</td>\n",
       "      <td>-0.583832</td>\n",
       "      <td>-0.677929</td>\n",
       "      <td>1.108185</td>\n",
       "      <td>-0.626652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.260347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357215</td>\n",
       "      <td>0.357215</td>\n",
       "      <td>-0.517360</td>\n",
       "      <td>1.956586</td>\n",
       "      <td>-0.651455</td>\n",
       "      <td>0.420116</td>\n",
       "      <td>-0.626652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.852191</td>\n",
       "      <td>-0.377549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.857556</td>\n",
       "      <td>-0.129157</td>\n",
       "      <td>-1.093932</td>\n",
       "      <td>-0.267952</td>\n",
       "      <td>-0.626652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.560987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.581894</td>\n",
       "      <td>-0.581894</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-1.345494</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>-0.267952</td>\n",
       "      <td>-0.626652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.151982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141458</td>\n",
       "      <td>0.141458</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>0.315589</td>\n",
       "      <td>-0.040317</td>\n",
       "      <td>0.282503</td>\n",
       "      <td>-0.626652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0         Cash loans           M            N               Y             0   \n",
       "1         Cash loans           F            N               N             0   \n",
       "2    Revolving loans           M            Y               Y             0   \n",
       "3         Cash loans           F            N               Y             0   \n",
       "4         Cash loans           M            N               Y             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE NAME_TYPE_SUITE  \\\n",
       "0          202500.0    406597.5      24700.5         351000.0   Unaccompanied   \n",
       "1          270000.0   1293502.5      35698.5        1129500.0          Family   \n",
       "2           67500.0    135000.0       6750.0         135000.0   Unaccompanied   \n",
       "3          135000.0    312682.5      29686.5         297000.0   Unaccompanied   \n",
       "4          121500.0    513000.0      21865.5         513000.0   Unaccompanied   \n",
       "\n",
       "        ...       NEW_CAR_TO_EMPLOY_RATIO NEW_PHONE_TO_BIRTH_RATIO  \\\n",
       "0       ...                           NaN                 0.991563   \n",
       "1       ...                           NaN                -0.260347   \n",
       "2       ...                     -1.852191                -0.377549   \n",
       "3       ...                           NaN                -0.560987   \n",
       "4       ...                           NaN                -0.151982   \n",
       "\n",
       "  NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER NEW_CREDIT_TO_INCOME_RATIO  \\\n",
       "0                               NaN                  -0.698886   \n",
       "1                               NaN                   0.357215   \n",
       "2                               NaN                  -0.701880   \n",
       "3                               NaN                  -0.581894   \n",
       "4                               NaN                   0.141458   \n",
       "\n",
       "   LOAN_INCOME_RATIO  ANNUITY_INCOME_RATIO  ANNUITY LENGTH  \\\n",
       "0          -0.698886             -0.625479       -0.583832   \n",
       "1           0.357215             -0.517360        1.956586   \n",
       "2          -0.701880             -0.857556       -0.129157   \n",
       "3          -0.581894              0.408542       -1.345494   \n",
       "4           0.141458             -0.013178        0.315589   \n",
       "\n",
       "   WORKING_LIFE_RATIO  INCOME_PER_FAM  CHILDREN_RATIO  \n",
       "0           -0.677929        1.108185       -0.626652  \n",
       "1           -0.651455        0.420116       -0.626652  \n",
       "2           -1.093932       -0.267952       -0.626652  \n",
       "3            0.015787       -0.267952       -0.626652  \n",
       "4           -0.040317        0.282503       -0.626652  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "im = Imputer()\n",
    "temp = df_train.loc[:, ['DAYS_BIRTH', 'EXT_SOURCE_2']]\n",
    "temp = im.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6559337067313342"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test(GaussianNB(), temp, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = LGBMClassifier(\n",
    "nthread=4,\n",
    "            # is_unbalance=True,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=32,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.04,\n",
    "            reg_lambda=0.073,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=40,\n",
    "            silent=-1,\n",
    "            verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['a1'] = df_train.DAYS_BIRTH * df_train.EXT_SOURCE_2\n",
    "df_train['a2'] = df_train.DAYS_BIRTH * df_train.EXT_SOURCE_2 * df_train.EXT_SOURCE_3\n",
    "df_train['a3'] = df_train.DAYS_BIRTH / df_train.EXT_SOURCE_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723385497343698"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.get_dummies(df_train.loc[:, ['a3', 'DAYS_BIRTH', 'EXT_SOURCE_2',\n",
    "                                       'EXT_SOURCE_3', 'ORGANIZATION_TYPE', 'HOUR_APPR_PROCESS_START', 'AMT_ANNUITY']])\n",
    "feature_test(LGBMClassifier(), temp, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TARGET'] = TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TARGET']= df_train.TARGET.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 对 ORGANIZATION_TYPE聚类\n",
    "\n",
    "res = df_train.groupby(by='ORGANIZATION_TYPE')['TARGET'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4).fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 2, 3, 2, 2, 1, 0, 2, 3, 3,\n",
       "       2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 3, 2, 1, 2, 3, 1, 3, 1, 3, 1, 3, 2,\n",
       "       2, 3, 2, 3, 1, 1, 1, 3, 1, 2, 0, 3, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = dict(zip(res.index, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ORGANIZATION_CLUSTER'] = df_train.ORGANIZATION_TYPE.map(map_dict)\n",
    "df_test['ORGANIZATION_CLUSTER'] = df_test.ORGANIZATION_TYPE.map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5627692813325408"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.get_dummies(df_train.loc[:, ['ORGANIZATION_CLUSTER']])\n",
    "feature_test(GaussianNB(), temp, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.index = train_id\n",
    "df_test.index = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((df_train.loc[:, 'ORGANIZATION_CLUSTER'], df_test.loc[:, 'ORGANIZATION_CLUSTER'])).to_csv(\"../../data/handled/new_features/orgnz.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ORGANIZATION_TYPE.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
