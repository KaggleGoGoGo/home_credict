{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/application_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/application_test.csv\")\n",
    "TARGET = df_train['TARGET']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_test.iloc[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_type(x):\n",
    "    if isinstance(x[0], str):\n",
    "        return 0\n",
    "    if len( np.unique(x[:400])) < 15:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def plot(x):\n",
    "    global TARGET\n",
    "    _type = get_type(x)\n",
    "    if _type == 0:\n",
    "        discrete_plot(x, TARGET)\n",
    "    else:\n",
    "        continuous_plot(x, TARGET)\n",
    "    \n",
    "def discrete_plot(x, y):\n",
    "    temp = pd.concat((x, y), axis=1)\n",
    "    temp['value'] = 1\n",
    "    temp = temp.dropna()\n",
    "    temp.groupby(list(temp.columns)[:2]).sum().unstack().plot(kind='bar')\n",
    "    print(temp.groupby([temp.columns[0]])['TARGET'].mean())\n",
    "    print(temp.groupby([temp.columns[0]])['TARGET'].count())\n",
    "    \n",
    "    \n",
    "\n",
    "def continuous_plot(x, y):\n",
    "    x = x.dropna()\n",
    "    sns.distplot(x.loc[y==0])\n",
    "    sns.distplot(x.loc[y==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['TARGET']\n",
    "df_train = df_train.iloc[:, 2:]\n",
    "df_test = df_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_1_train = df_train['EXT_SOURCE_1']\n",
    "ext_1_test = df_test['EXT_SOURCE_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_by_missing = df_train.columns[df_train.isnull().sum()/df_train.shape[0] < 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[feature_by_missing]\n",
    "df_test = df_test[feature_by_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns\n",
    "drop_num  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 4] = list(map(lambda x: 5 if x >= 5 else x, df_train.iloc[:, 4])) \n",
    "df_test.iloc[:, 4] = list(map(lambda x: 5 if x >= 5 else x, df_test.iloc[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    s = 50000\n",
    "    for i in range(12):\n",
    "        if x < s + 25000 * i:\n",
    "            return i\n",
    "    return 12\n",
    "\n",
    "df_train.iloc[:, 5] = list(map(lambda x:  replace(x), df_train.iloc[:, 5]))\n",
    "df_test.iloc[:, 5] = list(map(lambda x:  replace(x), df_test.iloc[:, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    s = 600000\n",
    "    for i in range(10):\n",
    "        if x < s + 100000 * i:\n",
    "            return i\n",
    "    return 10\n",
    "\n",
    "df_train.iloc[:, 6] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_train.iloc[:, 6]))\n",
    "df_test.iloc[:, 6] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_test.iloc[:, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "df_test.iloc[:, 7] = mean_std(np.log(df_test.iloc[:, 7]))\n",
    "df_train.iloc[:, 7] = mean_std(np.log(df_train.iloc[:, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    s = 400000\n",
    "    for i in range(4):\n",
    "        if x < s + 200000 * i:\n",
    "            return i\n",
    "    return 4\n",
    "\n",
    "df_train.iloc[:, 8] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_train.iloc[:, 8]))\n",
    "df_test.iloc[:, 8] = list(map(lambda x:  replace(x) if not pd.isnull(x) else x, df_test.iloc[:, 8]))\n",
    "# plot(df_train.iloc[:, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dic = {\n",
    "    'Children' : 1,\n",
    "    'Family' : 1,\n",
    "    'Spouse, partner': 1,\n",
    "    'Unaccompanied' : 0,\n",
    "    'Group of people': 2,\n",
    "    'Other_A': 2,\n",
    "    'Other_B': 2,\n",
    "}\n",
    "\n",
    "df_train.iloc[:, 9] = list(map(lambda x: map_dic[x] if not pd.isnull(x) else x, df_train.iloc[:, 9]))\n",
    "df_test.iloc[:, 9] = list(map(lambda x: map_dic[x] if not pd.isnull(x) else x, df_test.iloc[:, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dic = {\n",
    "    'Businessman':'bus_and_stu', 'Student':'bus_and_stu', \n",
    "    'Maternity leave': 'mat_and_une', 'Unemployed':'mat_and_une'\n",
    "}\n",
    "\n",
    "df_train.iloc[:, 10] = list(map(lambda x: map_dic[x] if x in map_dic else x, df_train.iloc[:, 10]))\n",
    "df_test.iloc[:, 10] = list(map(lambda x: map_dic[x] if x in map_dic else x, df_test.iloc[:, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 14] = pd.Series(list(map(lambda x: 1 if x >= 0.03 else 0 if not pd.isnull(x) else x, df_train.iloc[:, 14])))\n",
    "df_test.iloc[:, 14] = pd.Series(list(map(lambda x: 1 if x >= 0.03 else 0 if not pd.isnull(x) else x, df_test.iloc[:, 14])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重要特征！\n",
    "df_train['days_birth_dummy'] = list(map(lambda x: 1 if x > -15000 else 0 if not pd.isnull(x) else x, df_train.iloc[:, 15]))\n",
    "df_test['days_birth_dummy'] = list(map(lambda x: 1 if x > -15000 else 0 if not pd.isnull(x) else x, df_test.iloc[:, 15]))\n",
    "df_train.iloc[:, 15] = mean_std(df_train.iloc[:, 15])\n",
    "df_test.iloc[:, 15] = mean_std(df_test.iloc[:, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['days_employed_dummy'] = df_train.iloc[:, 16].map(lambda x: '2' if x>0 else '1' if x > -2100 else '0' if not pd.isnull(x) else x)\n",
    "df_test['days_employed_dummy'] = df_test.iloc[:, 16].map(lambda x: '2' if x>0 else '1' if x > -2100 else '0' if not pd.isnull(x) else x)\n",
    "\n",
    "\n",
    "df_test.iloc[:, 16] = mean_std(df_test.iloc[:, 16].map(lambda x: np.nan if x>0 else x))\n",
    "df_train.iloc[:, 16] = mean_std(df_train.iloc[:, 16].map(lambda x: np.nan if x>0 else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['days_registration_dummy'] = df_train.iloc[:, 17].map(lambda x: 1 if x> -6000 else 0 if not pd.isnull(x) else x)\n",
    "df_test['days_registration_dummy'] = df_test.iloc[:, 17].map(lambda x: 1 if x>-6000 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 17] = mean_std(df_test.iloc[:, 17])\n",
    "df_train.iloc[:, 17] = mean_std(df_train.iloc[:, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['days_idpub_dummy'] = df_train.iloc[:, 18].map(lambda x: 1 if x> -3100 else 0 if not pd.isnull(x) else x)\n",
    "df_test['days_idpub_dummy'] = df_test.iloc[:, 18].map(lambda x: 1 if x>-3100 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 18] = mean_std(df_test.iloc[:, 18])\n",
    "df_train.iloc[:, 18] = mean_std(df_train.iloc[:, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.drop(columns=columns[19])\n",
    "#df_test = df_test.drop(columns=columns[19])\n",
    "drop_num.append(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 26] = df_train.iloc[:, 26].map(lambda x: 6 if x >= 6 else x)\n",
    "df_test.iloc[:, 26] = df_test.iloc[:, 26].map(lambda x: 6 if x >= 6 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 30] = df_train.iloc[:, 30].map(lambda x: 1 if x >= 13 else 0 if not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 30] = df_test.iloc[:, 30].map(lambda x: 1 if x >= 13 else 0 if not pd.isnull(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO High-Cardinality Categorical  Cluster\n",
    "# plot(df_train.iloc[:, 34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ext_source_2_dummy'] = df_train.iloc[:, 38].map(lambda x: 1 if x> 0.5 else 0 if not pd.isnull(x) else x)\n",
    "df_test['ext_source_2_dummy'] = df_test.iloc[:, 38].map(lambda x: 1 if x> 0.5 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 38] = mean_std(df_test.iloc[:, 38])\n",
    "df_train.iloc[:, 38] = mean_std(df_train.iloc[:, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ext_source_3_dummy'] = df_train.iloc[:, 39].map(lambda x: 1 if x> 0.42 else 0 if not pd.isnull(x) else x)\n",
    "df_test['ext_source_3_dummy'] = df_test.iloc[:, 39].map(lambda x: 1 if x> 0.42 else 0 if not pd.isnull(x) else x)\n",
    "\n",
    "df_test.iloc[:, 39] = mean_std(df_test.iloc[:, 39])\n",
    "df_train.iloc[:, 39] = mean_std(df_train.iloc[:, 39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 40] = df_train.iloc[:, 40].map(lambda x: x if x < 5   else np.nan)\n",
    "df_test.iloc[:, 40] = df_test.iloc[:, 40].map(lambda x: x if x < 5  else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 41] = df_train.iloc[:, 41].map(lambda x: x if x <= 5 else np.nan)\n",
    "df_test.iloc[:, 41] = df_test.iloc[:, 41].map(lambda x: x if x <= 5 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 42] = df_train.iloc[:, 42].map(lambda x: x if x <= 5 else np.nan)\n",
    "df_test.iloc[:, 42] = df_test.iloc[:, 42].map(lambda x: x if x <= 5 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 43] = df_train.iloc[:, 43].map(lambda x: x if x <= 2 else 3 if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 43] = df_test.iloc[:, 43].map(lambda x: x if x <= 2 else 3 if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 44] = df_train.iloc[:, 44].map(lambda x: '0' if x < -1000 else '1' if x < 0 else '2' if not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 44] = df_test.iloc[:, 44].map(lambda x: '0' if x < -1000 else '1' if x < 0 else '2' if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(45)\n",
    "drop_num.append(47)\n",
    "drop_num.append(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_num.append(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 65] = df_train.iloc[:, 65].map(lambda x: 0 if x ==0 else 1 if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 65] = df_test.iloc[:, 65].map(lambda x: 0 if x ==0 else 1 if  not pd.isnull(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 66] = df_train.iloc[:, 66].map(lambda x: 0 if x ==0 else 1 if  not pd.isnull(x) else x)\n",
    "df_test.iloc[:, 66] = df_test.iloc[:, 66].map(lambda x: 0 if x ==0 else 1 if  not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 67] = df_train.iloc[:, 67].map(lambda x: 2 if x >= 2 else x)\n",
    "df_test.iloc[:, 67] = df_test.iloc[:, 67].map(lambda x: 2 if x >= 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 68] = df_train.iloc[:, 68].map(lambda x: 2 if x >= 2 else x)\n",
    "df_test.iloc[:, 68] = df_test.iloc[:, 68].map(lambda x: 2 if x >= 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 69] = df_train.iloc[:, 69].map(lambda x: 2 if x >= 2 else x)\n",
    "df_test.iloc[:, 69] = df_test.iloc[:, 69].map(lambda x: 2 if x >= 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 70] = df_train.iloc[:, 70].map(lambda x: 5 if x >= 5 else x)\n",
    "df_test.iloc[:, 70] = df_test.iloc[:, 70].map(lambda x: 5 if x >= 5 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=columns[drop_num])\n",
    "df_test = df_test.drop(columns=columns[drop_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['EXT_SOURCE_1'] = ext_1_train\n",
    "df_test['EXT_SOURCE_1'] = ext_1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(df_train).values\n",
    "y = TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer()\n",
    "x = imp.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74207312, 0.73893272, 0.74501591])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "cross_val_score(lr, x, y, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dummy = pd.get_dummies(df_train)\n",
    "df_test_dummy = pd.get_dummies(df_test)\n",
    "\n",
    "train, test = df_train_dummy.align(df_test_dummy, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer()\n",
    "train = imp.fit_transform(train)\n",
    "test = imp.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-4aca3421f1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "lr.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(test_id, test_prob, sid=0):\n",
    "    result = pd.DataFrame(np.column_stack((test_id, test_prob)))\n",
    "    result.columns = ['SK_ID_CURR', 'TARGET']\n",
    "    result['SK_ID_CURR'] = result['SK_ID_CURR'].astype('int')\n",
    "    result.to_csv('submission' + str(sid) + '.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=48744, step=1)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = df_test.index\n",
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = lr.predict_proba(test)\n",
    "output(test_id, pre[:, 1], '20180701')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] [2018-07-02 09:04:12,642:AutoML(1):025aa001a19a3b418133b21a247be1f6] Error creating dummy predictions: {'error': 'Memout (used more than 3072 MB).', 'configuration_origin': 'DUMMY'} \n",
      "[WARNING] [2018-07-02 09:04:15,189:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-07-02 09:04:15,189:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No models fitted!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-45da29990823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mautoml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, metric, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \"\"\"\n\u001b[1;32m    399\u001b[0m         return super().fit(X=X, y=y, metric=metric, feat_type=feat_type,\n\u001b[0;32m--> 400\u001b[0;31m                            dataset_name=dataset_name)\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_automl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     def fit_ensemble(self, y, task=None, metric=None, precision='32',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, metric, loss, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_target_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m     def fit_ensemble(self, y, task=None, metric=None, precision='32',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, task, metric, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m    187\u001b[0m                                             dataset_name=dataset_name)\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_data_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_automl_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, datamanager, metric)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc_ensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36m_load_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resampling_strategy\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0;34m'partial-cv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'partial-cv-iterative-fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No models fitted!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No models fitted!"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification as ac\n",
    "automl = ac.AutoSklearnClassifier()\n",
    "automl.fit(train, y)\n",
    "pred = automl.predict_proba(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
