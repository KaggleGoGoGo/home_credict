{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_train = pd.read_csv('../data/handled/main_train.csv', index_col=0)\n",
    "df_main_test = pd.read_csv('../data/handled/main_test.csv', index_col=0)\n",
    "\n",
    "df_bureau_train = pd.read_csv('../data/handled/bureau_train.csv', index_col=0)\n",
    "df_bureau_test = pd.read_csv('../data/handled/bureau_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_test.index = df_bureau_test.SK_ID_CURR\n",
    "df_bureau_train.index = df_bureau_train.SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_train = df_bureau_train.drop(columns='SK_ID_CURR')\n",
    "df_bureau_test = df_bureau_test.drop(columns='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_main_train.TARGET\n",
    "\n",
    "df_main_train = df_main_train.drop(columns='TARGET')\n",
    "#df_main_test = df_main_test.drop(columns='TARGET')\n",
    "df_bureau_train = df_bureau_train.drop(columns='TARGET')\n",
    "df_bureau_test = df_bureau_test.drop(columns='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_main_train, df_bureau_train, left_index=True, right_index=True)\n",
    "df_test = pd.merge(df_main_test, df_bureau_test, left_index=True, right_index=True)\n",
    "df_train = df_train.drop(columns='SK_ID_CURR.1')\n",
    "df_test = df_test.drop(columns='SK_ID_CURR.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge other tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/handled/previous_application_handled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(df, how='left')\n",
    "df_test = df_test.join(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/handled/POS_CASH_balance.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(df, how='left')\n",
    "df_test = df_test.join(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/handled/installments_payments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(df, how='left')\n",
    "df_test = df_test.join(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/handled/credit_card_balance.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(df, how='left')\n",
    "df_test = df_test.join(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 596)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, dummy_na=True)\n",
    "df_test = pd.get_dummies(df_test, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_train.align(df_test, join='left', fill_value=0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/handled/train.csv')\n",
    "df_test.to_csv('../data/handled/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Imputer()\n",
    "im.fit(df_train)\n",
    "train = im.transform(df_train)\n",
    "test = im.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "res = lr.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_bureau_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(test_id, test_prob, sid=0):\n",
    "    result = pd.DataFrame(np.column_stack((test_id, test_prob)))\n",
    "    result.columns = ['SK_ID_CURR', 'TARGET']\n",
    "    result['SK_ID_CURR'] = result['SK_ID_CURR'].astype('int')\n",
    "    result.to_csv('submission' + str(sid) + '.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output(test_id, res[:, 1], sid='_add_bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(est, x, y, support=None):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "    #sfm = SelectFromModel(LogisticRegression(penalty='l1'), 0.02)\n",
    "    #sfm.fit(x_train, y_train)\n",
    "    if support:\n",
    "        x_train = x_train[:, support]\n",
    "        x_test = x_test[:, support]\n",
    "    \n",
    "    est.fit(x_train, y_train)\n",
    "    y_predict = est.predict_proba(x_test)\n",
    "    auc_score = get_auc_score(y_test, y_predict[:, 1])\n",
    "    return auc_score\n",
    "\n",
    "\n",
    "def get_auc_score(y_true, y_predict_proba):\n",
    "    f, t, _ = roc_curve(y_true, y_predict_proba, pos_label=1)\n",
    "    return auc(f, t)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfm = SelectFromModel(LogisticRegression(penalty='l1'), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=0.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sfm.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sfm.get_support().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关系数和sfm同时进行特征选择\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def corr(x, y):\n",
    "#     df = pd.DataFrame(np.column_stack((x, y)))\n",
    "#     df = df.dropna()\n",
    "#     return df.corr().values[0, 1]\n",
    "\n",
    "# corr = list(map(lambda x: corr(x, y_train), train.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7476609332421753"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(xgb_model, train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(np.column_stack((df_train.columns, xgb_model.feature_importances_)))\n",
    "res = res.loc[res[1] !=0]\n",
    "#res.sort_values(by=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vec = xgb_model.feature_importances_ != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 贝叶斯调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "\n",
    "def xgb_evaluate(eta,\n",
    "                            min_child_weight,\n",
    "                            cosample_bytree,\n",
    "                            max_depth,\n",
    "                            subsample,\n",
    "                            gamma,\n",
    "                            alpha):\n",
    "    global params, xgb, xgtrain, num_rounds, random_state\n",
    "    params['eta'] = max(eta, 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(cosample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "    \n",
    "    cv = xgb.cv(params, xgtrain, num_boost_round=num_rounds, metrics='auc', early_stopping_rounds=50,\n",
    "                nfold=5, seed=random_state, callbacks=[xgb.callback.early_stop(50)])\n",
    "    return cv['test-auc-mean'].values[-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train[:, support_vec], label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   cosample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[696]\ttrain-auc:0.761426+0.00127904\ttest-auc:0.75355+0.00340667\n",
      "\n",
      "    1 | 29m46s | \u001b[35m   0.75355\u001b[0m | \u001b[32m   7.5220\u001b[0m | \u001b[32m           0.9244\u001b[0m | \u001b[32m   0.2803\u001b[0m | \u001b[32m   2.5626\u001b[0m | \u001b[32m     7.3636\u001b[0m | \u001b[32m           15.9469\u001b[0m | \u001b[32m     0.5370\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[262]\ttrain-auc:0.762515+0.000899799\ttest-auc:0.75073+0.00339422\n",
      "\n",
      "    2 | 19m46s |    0.75073 |    4.4726 |            0.6821 |    0.4361 |    3.0286 |     11.3313 |            14.2157 |      0.7941 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[434]\ttrain-auc:0.76443+0.00114953\ttest-auc:0.750439+0.00329701\n",
      "\n",
      "    3 | 31m12s |    0.75044 |    0.0127 |            0.9450 |    0.3438 |    3.8019 |     11.2825 |             3.7698 |      0.5080 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[23]\ttrain-auc:0.776594+0.00110042\ttest-auc:0.749124+0.00279957\n",
      "\n",
      "    4 | 06m06s |    0.74912 |    9.8361 |            0.1057 |    0.3644 |    0.8133 |     13.9125 |             2.7650 |      0.5649 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[176]\ttrain-auc:0.748809+0.00146699\ttest-auc:0.743566+0.00382214\n",
      "\n",
      "    5 | 17m48s |    0.74357 |    5.1691 |            0.3063 |    0.2397 |    7.8796 |     13.4726 |             3.9278 |      0.8511 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   cosample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-auc:0.791187+0.000511059\ttest-auc:0.755784+0.00330773\n",
      "\n",
      "    6 | 03m44s | \u001b[35m   0.75578\u001b[0m | \u001b[32m   0.1896\u001b[0m | \u001b[32m           0.1011\u001b[0m | \u001b[32m   0.1950\u001b[0m | \u001b[32m   0.0606\u001b[0m | \u001b[32m     5.1792\u001b[0m | \u001b[32m           14.7006\u001b[0m | \u001b[32m     0.8916\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-auc:0.77639+0.000468613\ttest-auc:0.751258+0.00245328\n",
      "\n",
      "    7 | 03m17s |    0.75126 |    0.5150 |            0.9380 |    0.2416 |    0.2543 |      5.1629 |            19.6374 |      0.5382 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-auc:0.791311+0.000786217\ttest-auc:0.756863+0.0028806\n",
      "\n",
      "    8 | 03m50s | \u001b[35m   0.75686\u001b[0m | \u001b[32m   8.9948\u001b[0m | \u001b[32m           0.9602\u001b[0m | \u001b[32m   0.3387\u001b[0m | \u001b[32m   0.4926\u001b[0m | \u001b[32m     5.2259\u001b[0m | \u001b[32m            1.6529\u001b[0m | \u001b[32m     0.9901\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.07301196e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[57]\ttrain-auc:0.77252+0.000910023\ttest-auc:0.751984+0.0030076\n",
      "\n",
      "    9 | 03m36s |    0.75198 |    0.0920 |            0.1406 |    0.2458 |    1.2795 |      5.1447 |             1.4981 |      0.5186 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[194]\ttrain-auc:0.817735+0.000626569\ttest-auc:0.760405+0.00238065\n",
      "\n",
      "   10 | 07m38s | \u001b[35m   0.76040\u001b[0m | \u001b[32m   9.6523\u001b[0m | \u001b[32m           0.9604\u001b[0m | \u001b[32m   0.1171\u001b[0m | \u001b[32m   0.1790\u001b[0m | \u001b[32m     6.9201\u001b[0m | \u001b[32m           12.9632\u001b[0m | \u001b[32m     0.9609\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-auc:0.779062+0.000833663\ttest-auc:0.752823+0.0028019\n",
      "\n",
      "   11 | 02m37s |    0.75282 |    9.8138 |            0.7646 |    0.4604 |    0.3065 |      5.2719 |            13.4611 |      0.9538 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[80]\ttrain-auc:0.788713+0.000867949\ttest-auc:0.753793+0.00272788\n",
      "\n",
      "   12 | 04m18s |    0.75379 |    2.8259 |            0.9774 |    0.1995 |    0.0055 |      5.6413 |             7.5256 |      0.5366 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[37]\ttrain-auc:0.745315+0.000707382\ttest-auc:0.740893+0.00500768\n",
      "\n",
      "   13 | 02m31s |    0.74089 |    1.1022 |            0.9032 |    0.1000 |    9.5039 |      5.5656 |            19.6865 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-auc:0.889075+0.00116233\ttest-auc:0.738737+0.00422155\n",
      "\n",
      "   14 | 06m12s |    0.73874 |    0.7549 |            0.2135 |    0.1106 |    0.1816 |     13.6929 |            18.9667 |      0.7579 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.84352475e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[250]\ttrain-auc:0.741361+0.00133717\ttest-auc:0.738356+0.00483395\n",
      "\n",
      "   15 | 09m15s |    0.73836 |    0.0000 |            1.0000 |    0.1000 |   10.0000 |      5.0000 |             1.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[41]\ttrain-auc:0.856648+0.00128225\ttest-auc:0.752513+0.00240984\n",
      "\n",
      "   16 | 04m35s |    0.75251 |    1.0320 |            0.9683 |    0.1452 |    0.4069 |      9.6462 |             1.3375 |      0.9985 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.77398346e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[222]\ttrain-auc:0.744103+0.000977139\ttest-auc:0.740653+0.00493614\n",
      "\n",
      "   17 | 22m43s |    0.74065 |   10.0000 |            1.0000 |    0.1000 |    9.7253 |     13.9751 |            12.8517 |      0.6927 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00014133]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[510]\ttrain-auc:0.758407+0.000857176\ttest-auc:0.751716+0.0038372\n",
      "\n",
      "   18 | 20m21s |    0.75172 |    9.7325 |            0.5763 |    0.1103 |    3.9493 |      7.6420 |             6.7425 |      0.9093 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[72]\ttrain-auc:0.852982+0.000934866\ttest-auc:0.756444+0.00293179\n",
      "\n",
      "   19 | 07m56s |    0.75644 |    9.8838 |            0.8963 |    0.1011 |    0.0555 |     11.6548 |            19.6546 |      0.8368 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[86]\ttrain-auc:0.828411+0.00095252\ttest-auc:0.756735+0.00251677\n",
      "\n",
      "   20 | 07m52s |    0.75674 |    9.5613 |            0.1204 |    0.1078 |    0.0666 |      9.9935 |            13.6121 |      0.5391 | \n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-auc:0.802482+0.000944338\ttest-auc:0.753127+0.00256212\n",
      "\n",
      "   21 | 04m17s |    0.75313 |    9.9978 |            0.8476 |    0.2269 |    0.0419 |      8.8446 |             1.5869 |      0.6749 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.9825587e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[936]\ttrain-auc:0.783759+0.000371222\ttest-auc:0.760161+0.00314282\n",
      "\n",
      "   22 | 84m03s |    0.76016 |    9.8471 |            0.9138 |    0.1259 |    1.6029 |     14.9452 |             9.0917 |      0.8392 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "num_rounds = 3000\n",
    "random_state = 918\n",
    "num_iter = 25\n",
    "init_points = 5\n",
    "params = {\n",
    "    'silent' : 1,\n",
    "    'nthread': 4,\n",
    "    'eval_metric' : 'auc',\n",
    "    'verbose_eval' : True,\n",
    "    'seed': random_state,\n",
    "}\n",
    "\n",
    "xgbBO = BayesianOptimization(xgb_evaluate, {\n",
    "                                            'eta':(0.1, 0.5),\n",
    "                                            'min_child_weight' : (1, 20),\n",
    "                                            'cosample_bytree' : (0.1, 1),\n",
    "                                            'max_depth' : (5, 15),\n",
    "                                            'subsample' : (0.5, 1),\n",
    "                                            'gamma': (0, 10),\n",
    "                                            'alpha': (0, 10)\n",
    "                                        })\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step |   Time |      Value |     alpha |   cosample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
    "10 | 07m38s |    0.76040 |    9.6523 |            0.9604 |    0.1171 |    0.1790 |      6.9201 |            12.9632 |      0.9609 | \n",
    "22 | 84m03s |    0.76016 |    9.8471 |            0.9138 |    0.1259 |    1.6029 |     14.9452 |             9.0917 |      0.8392 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'silent' : 1,\n",
    "    'nthread': 4,\n",
    "    'eval_metric' : 'auc',\n",
    "    'verbose_eval' : True,\n",
    "    'seed': 918,\n",
    "    'alpha': 9.6523,\n",
    "    'cosample_bytree': 0.9604,\n",
    "    'eta': 0.1171,\n",
    "    'gamma': 0.179,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight':13,\n",
    "    'subsample': 0.9609\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=9.6523, base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=1, colsample_bytree=1, cosample_bytree=0.9604,\n",
       "       eta=0.1171, eval_metric='auc', gamma=0.179, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=7, min_child_weight=13, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=918, silent=1, subsample=0.9609, verbose_eval=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(**params)\n",
    "model.fit(train[:, support_vec], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict_proba(test[:, support_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output(test_id, y_predict[:, 1], sid='_xgboost_and_bayes')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
