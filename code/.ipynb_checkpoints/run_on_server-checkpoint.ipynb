{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "import gc\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def data_prepare(num=None):\n",
    "    train = pd.read_csv('../data/handled/train.csv', nrows=num, index_col=0)\n",
    "    test = pd.read_csv('../data/handled/test.csv', nrows=num, index_col=0)\n",
    "    y_train = pd.read_csv('../data/handled/y_train.csv', nrows=num, header=-1, index_col=0)\n",
    "    return train, test, y_train\n",
    "\n",
    "\n",
    "def output_result(test_id, test_prob, sid=''):\n",
    "    result = pd.DataFrame(np.column_stack((test_id, test_prob)))\n",
    "    result.columns = ['SK_ID_CURR', 'TARGET']\n",
    "    result['SK_ID_CURR'] = result['SK_ID_CURR'].astype('int')\n",
    "    result.to_csv('./submission/submission_' + str(sid) + '.csv', header=True, index=False)\n",
    "\n",
    "\n",
    "def show_importance(model, num=20, height=0.8):\n",
    "    xgb.plot_importance(model, max_num_features=num, height=height)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def xgb_k_folder_cv(params, xgtrain, fold=5, seed=918):\n",
    "    cv = xgb.cv(params, xgtrain, metrics='auc', early_stopping_rounds=50,\n",
    "                nfold=fold, seed=seed)\n",
    "    return cv   # ['test-auc-mean'].values[-1]\n",
    "\n",
    "\n",
    "def xgb_evaluate(params,\n",
    "                 xgtrain,\n",
    "                 #   以下需要再次调用匿名函数封装\n",
    "                 eta,\n",
    "                 min_child_weight,\n",
    "                 cosample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "    params['eta'] = max(eta, 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(cosample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "    cv = xgb.cv(params, xgtrain, metrics='auc', early_stopping_rounds=50,\n",
    "                nfold=5, seed=918)\n",
    "    return cv['test-auc-mean'].values[-1]\n",
    "\n",
    "\n",
    "def xgb_no_feature_select(train: pd.DataFrame, test: pd.DataFrame, y_train, cv=False):\n",
    "    params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': 918,\n",
    "        'alpha': 9.6523,\n",
    "        'cosample_bytree': 0.9604,\n",
    "        'eta': 0.1171,\n",
    "        'gamma': 0.179,\n",
    "        'max_depth': 7,\n",
    "        'min_child_weight': 13,\n",
    "        'subsample': 0.9609\n",
    "    }\n",
    "    xgtrain = xgb.DMatrix(train, label=y_train)\n",
    "    if cv:\n",
    "        cv_res = xgb_k_folder_cv(params, xgtrain)\n",
    "        print(cv_res)\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(train, y_train)\n",
    "    y_predict = model.predict_proba(test)\n",
    "    return model, y_predict\n",
    "\n",
    "\n",
    "def get_select_ids(importance, top_num=None):\n",
    "    if top_num:\n",
    "        threshold = np.sort(importance)[-top_num-1]\n",
    "    else:\n",
    "        threshold = 0\n",
    "    select_id = [True if i > threshold else False for i in importance]\n",
    "    return select_id\n",
    "\n",
    "def xgb_feature_select(train, test, y_train, importance, top_num=None, cv=False):\n",
    "    select_id = get_select_ids(importance, top_num)\n",
    "    train = train.loc[:, select_id]\n",
    "    test = test.loc[:, select_id]\n",
    "    params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': 918,\n",
    "        'alpha': 9.6523,\n",
    "        'cosample_bytree': 0.9604,\n",
    "        'eta': 0.1171,\n",
    "        'gamma': 0.179,\n",
    "        'max_depth': 7,\n",
    "        'min_child_weight': 13,\n",
    "        'subsample': 0.9609\n",
    "    }\n",
    "    xgtrain = xgb.DMatrix(train, label=y_train)\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "    if cv:\n",
    "        cv_res = xgb_k_folder_cv(params, xgtrain)\n",
    "        print(cv_res)\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(train, y_train)\n",
    "    y_predict = model.predict_proba(test)\n",
    "    return model, y_predict\n",
    "\n",
    "\n",
    "def xgb_bayes_opt(train, y_train):\n",
    "    # num_rounds = 3000\n",
    "    random_state = 918\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state,\n",
    "    }\n",
    "    xgtrian = xgb.DMatrix(train, label=y_train)\n",
    "    _xgb_evaluate = lambda eta, min_child_weight, cosample_bytree, max_depth, subsample, gamma, alpha: xgb_evaluate(params, \n",
    "                                                                                                                    xgtrian, eta, min_child_weight, cosample_bytree, max_depth, subsample, gamma, alpha)\n",
    "    xgbBO = BayesianOptimization(_xgb_evaluate, {\n",
    "        'eta': (0.1, 0.5),\n",
    "        'min_child_weight': (1, 20),\n",
    "        'cosample_bytree': (0.1, 1),\n",
    "        'max_depth': (5, 15),\n",
    "        'subsample': (0.5, 1),\n",
    "        'gamma': (0, 10),\n",
    "        'alpha': (0, 10)\n",
    "    })\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    return xgbBO\n",
    "\n",
    "\n",
    "def xgb_unbalance_handle(train, test):\n",
    "    pass\n",
    "\n",
    "\n",
    "def models_stack(trian, test):\n",
    "    pass\n",
    "\n",
    "\n",
    "def other_feature_select_method():\n",
    "    pass\n",
    "\n",
    "\n",
    "def xgb_other_params_adj():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train  = data_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Imputer()\n",
    "train = im.fit_transform(df_train.values)\n",
    "test = im.transform(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.707869       0.001570       0.701674      0.005074\n",
      "1        0.717715       0.002910       0.709581      0.005716\n",
      "2        0.724155       0.001126       0.714875      0.006228\n",
      "3        0.729238       0.001824       0.718391      0.005958\n",
      "4        0.735447       0.001496       0.722992      0.006305\n",
      "5        0.740085       0.001239       0.726137      0.006038\n",
      "6        0.743385       0.000927       0.728394      0.006291\n",
      "7        0.747936       0.001394       0.732213      0.005573\n",
      "8        0.751383       0.001561       0.734831      0.005485\n",
      "9        0.754769       0.001466       0.736970      0.005613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 不处理缺失值\n",
    "model_1, predict_1 = xgb_no_feature_select(df_train, df_test, y_train, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 处理缺失值，不做特征选择\n",
    "model_2, predict_2 = xgb_no_feature_select(train, test, y_train, cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.705940       0.001702       0.700791      0.004070\n",
      "1        0.715977       0.001601       0.708964      0.005218\n",
      "2        0.721559       0.001921       0.713096      0.004604\n",
      "3        0.729107       0.003050       0.719017      0.004984\n",
      "4        0.734947       0.001923       0.723125      0.005808\n",
      "5        0.738053       0.001160       0.725641      0.005626\n",
      "6        0.741941       0.001742       0.728415      0.005118\n",
      "7        0.746078       0.001233       0.731368      0.005458\n",
      "8        0.749308       0.000856       0.733661      0.005486\n",
      "9        0.752145       0.000717       0.735624      0.005890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 处理缺失值， 在model_2基础上做特征选择，剔除importance为0的变量\n",
    "model_3, predict_3 = xgb_feature_select(pd.DataFrame(train), pd.DataFrame(test), y_train, model_2.feature_importances_ cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.706042       0.001785       0.701831      0.004747\n",
      "1        0.714816       0.001182       0.709383      0.006181\n",
      "2        0.721308       0.002198       0.714526      0.005455\n",
      "3        0.727664       0.003177       0.719543      0.004026\n",
      "4        0.732737       0.001711       0.723735      0.005447\n",
      "5        0.737351       0.001959       0.727239      0.005994\n",
      "6        0.741039       0.001453       0.730273      0.005834\n",
      "7        0.744264       0.001350       0.732804      0.005809\n",
      "8        0.747553       0.001487       0.735507      0.005466\n",
      "9        0.750888       0.001121       0.737955      0.006092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 处理缺失值， 在model_2基础上做特征选择，剔除importance排名50以后的变量（目前效果最好）\n",
    "model_4, predict_4 = xgb_feature_select(pd.DataFrame(train), pd.DataFrame(test), y_train, model_2.feature_importances_, top_num=50, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 处理缺失值，用lasso进行特征选择\n",
    "# clf = LassoCV()\n",
    "# sfm = SelectFromModel(LogisticRegression(penalty='l1', C=0.2))\n",
    "# sfm.fit(train, y_train)\n",
    "\n",
    "\n",
    "# train2 = sfm.transform(train)\n",
    "# test2 = sfm.transform(test)\n",
    "\n",
    "# train2.shape\n",
    "\n",
    "# model_5, predict_5 = xgb_no_feature_select(train2, test2, y_train, cv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择前50个特征进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_id = get_select_ids( model_2.feature_importances_, top_num=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   cosample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m47s | \u001b[35m   0.70602\u001b[0m | \u001b[32m   3.0266\u001b[0m | \u001b[32m           0.9476\u001b[0m | \u001b[32m   0.4695\u001b[0m | \u001b[32m   0.1433\u001b[0m | \u001b[32m    14.3798\u001b[0m | \u001b[32m            5.9790\u001b[0m | \u001b[32m     0.7988\u001b[0m | \n",
      "    2 | 00m33s | \u001b[35m   0.74914\u001b[0m | \u001b[32m   8.4436\u001b[0m | \u001b[32m           0.9429\u001b[0m | \u001b[32m   0.2094\u001b[0m | \u001b[32m   2.5442\u001b[0m | \u001b[32m    11.9146\u001b[0m | \u001b[32m            1.4303\u001b[0m | \u001b[32m     0.9731\u001b[0m | \n",
      "    3 | 00m39s | \u001b[35m   0.75593\u001b[0m | \u001b[32m   2.5162\u001b[0m | \u001b[32m           0.3097\u001b[0m | \u001b[32m   0.4260\u001b[0m | \u001b[32m   2.5674\u001b[0m | \u001b[32m    12.2332\u001b[0m | \u001b[32m           14.4849\u001b[0m | \u001b[32m     0.9831\u001b[0m | \n",
      "    4 | 00m29s | \u001b[35m   0.75621\u001b[0m | \u001b[32m   9.3030\u001b[0m | \u001b[32m           0.2299\u001b[0m | \u001b[32m   0.2879\u001b[0m | \u001b[32m   0.9435\u001b[0m | \u001b[32m    10.4910\u001b[0m | \u001b[32m           19.7425\u001b[0m | \u001b[32m     0.8880\u001b[0m | \n",
      "    5 | 00m28s |    0.74724 |    3.7619 |            0.7515 |    0.4096 |    9.8337 |      9.8814 |            13.4564 |      0.9403 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   cosample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 00m20s |    0.73196 |    0.0000 |            0.1000 |    0.1000 |    0.0000 |      5.0000 |             1.0000 |      1.0000 | \n",
      "    7 | 00m25s |    0.73344 |    0.0000 |            1.0000 |    0.1000 |    0.0000 |      5.0000 |            20.0000 |      0.5000 | \n",
      "    8 | 00m27s |    0.73842 |   10.0000 |            0.1000 |    0.5000 |   10.0000 |      5.0000 |             1.0000 |      0.5000 | \n",
      "    9 | 01m02s |    0.72822 |    0.0000 |            0.1000 |    0.1000 |   10.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "   10 | 00m29s |    0.72827 |   10.0000 |            0.1000 |    0.1000 |    0.0000 |      5.0000 |             6.8924 |      1.0000 | \n",
      "   11 | 00m54s |    0.72208 |   10.0000 |            0.1000 |    0.1000 |   10.0000 |     15.0000 |             1.0000 |      1.0000 | \n",
      "   12 | 00m25s |    0.72462 |    0.0000 |            1.0000 |    0.1000 |   10.0000 |      5.0000 |             1.0000 |      1.0000 | \n",
      "   13 | 01m00s |    0.74916 |   10.0000 |            1.0000 |    0.5000 |    7.3890 |     15.0000 |            19.9955 |      1.0000 | \n",
      "   14 | 00m23s |    0.75039 |    0.0000 |            0.1000 |    0.5000 |    8.0474 |      5.0003 |            20.0000 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.08468568e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 00m31s |    0.72737 |    8.4032 |            0.2459 |    0.1131 |    7.5971 |      8.1175 |            19.9348 |      0.9538 | \n",
      "   16 | 00m46s |    0.75168 |    9.6840 |            0.1720 |    0.3426 |    0.6509 |     14.9173 |            17.2413 |      0.5072 | \n",
      "   17 | 00m50s |    0.70919 |    1.4669 |            0.1000 |    0.5000 |    0.0000 |     13.5030 |            20.0000 |      1.0000 | \n",
      "   18 | 00m23s |    0.74843 |    0.1304 |            0.9735 |    0.4493 |    4.4563 |      5.4239 |            11.1289 |      0.5334 | \n",
      "   19 | 00m46s |    0.74831 |    9.9399 |            0.1212 |    0.4802 |    4.3441 |     13.0097 |             9.4828 |      0.5837 | \n",
      "   20 | 00m34s |    0.74415 |    4.1692 |            0.1000 |    0.5000 |    5.5960 |      9.0141 |             1.0000 |      0.5000 | \n",
      "   21 | 00m22s |    0.75152 |    8.0354 |            0.9687 |    0.4850 |    1.6274 |      5.0049 |             1.0000 |      0.5118 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.53359023e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 00m35s | \u001b[35m   0.75708\u001b[0m | \u001b[32m   7.4560\u001b[0m | \u001b[32m           1.0000\u001b[0m | \u001b[32m   0.4145\u001b[0m | \u001b[32m   1.3210\u001b[0m | \u001b[32m     9.6588\u001b[0m | \u001b[32m           14.9833\u001b[0m | \u001b[32m     0.9887\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.72254642e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 | 00m33s |    0.73800 |    0.0442 |            0.9040 |    0.1350 |    5.6013 |      9.8169 |            16.3595 |      0.8644 | \n",
      "   24 | 00m25s |    0.75547 |    4.5700 |            0.1800 |    0.4824 |    2.1971 |      6.1241 |            16.4240 |      0.9958 | \n",
      "   25 | 00m31s |    0.75537 |    9.8227 |            0.1630 |    0.4410 |    0.6713 |      8.9389 |             1.2392 |      0.7224 | \n",
      "   26 | 00m49s |    0.75231 |    5.7913 |            0.1032 |    0.4838 |    5.0950 |     13.1176 |            15.2090 |      0.9951 | \n",
      "   27 | 00m25s |    0.75423 |    0.0340 |            0.2073 |    0.4384 |    0.1598 |      6.6958 |            12.0528 |      0.9744 | \n",
      "   28 | 00m24s |    0.75484 |    9.3045 |            0.6895 |    0.4498 |    0.0445 |      5.5405 |            19.9142 |      0.7695 | \n",
      "   29 | 00m23s |    0.74738 |    0.0000 |            0.1000 |    0.5000 |   10.0000 |      5.0000 |            13.3978 |      0.8983 | \n",
      "   30 | 00m36s |    0.74588 |    4.1113 |            0.2558 |    0.4929 |    0.7343 |      9.2120 |            13.4877 |      0.5092 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bayes_opt.bayesian_optimization.BayesianOptimization at 0x7fae64235748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bayes_opt(train[:, select_id], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.710163       0.001028       0.704493      0.005373\n",
      "1        0.731842       0.001143       0.722752      0.005548\n",
      "2        0.745533       0.001212       0.733423      0.005197\n",
      "3        0.755561       0.001319       0.740539      0.004901\n",
      "4        0.762862       0.000590       0.745473      0.005074\n",
      "5        0.768425       0.001029       0.749519      0.004855\n",
      "6        0.772858       0.001076       0.752282      0.004501\n",
      "7        0.775894       0.000991       0.754436      0.004672\n",
      "8        0.778441       0.000856       0.756022      0.004437\n",
      "9        0.780419       0.000932       0.757220      0.004167\n"
     ]
    }
   ],
   "source": [
    "new_params = {\n",
    "        'silent': 1,\n",
    "        'nthread': 4,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose_eval': True,\n",
    "        'seed': 918,\n",
    "        'alpha': 7.4560,\n",
    "        'cosample_bytree': 1,\n",
    "        'eta': 0.4145,\n",
    "        'gamma': 1.3210,\n",
    "        'max_depth': 10,\n",
    "        'min_child_weight': 14.9833,\n",
    "        'subsample': 0.9887 \n",
    "}\n",
    "\n",
    "xgtrain = xgb.DMatrix(train[:, select_id], label=y_train)\n",
    "cv_res = xgb_k_folder_cv(new_params, xgtrain)\n",
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307511"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.arange(df_train.shape[0])\n",
    "np.random.seed(918)\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "idx_list = []\n",
    "num = df_train.shape[0] // 11\n",
    "for i in range(11):\n",
    "    if i != 0:\n",
    "        idx_list.append(idxs[i * num:(i+1) * num])\n",
    "    else:\n",
    "        idx_list.append(idxs[10 * num: ])\n",
    "\n",
    "length = 0\n",
    "for i in idx_list:\n",
    "    length += len(i)\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 LGB并且分11份进行融合\n",
    "\n",
    "对照表：https://blog.csdn.net/weiyongle1996/article/details/78446244/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (27961,) (47,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99816e82030d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mcls_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams_lgb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnew_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mnew_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcls_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (27961,) (47,) "
     ]
    }
   ],
   "source": [
    "params_lgb = {\n",
    "    'nthread': 4,\n",
    "    #is_unbalance=True,\n",
    "    'n_estimators' : 10000,\n",
    "    'learning_rate' : 0.4145,\n",
    "    #'num_leaves' : 32,\n",
    "    'colsample_bytree' : 1.0,\n",
    "    'subsample' : 0.9887,\n",
    "    'max_depth' : 10,\n",
    "    'reg_alpha' : 7.4560,\n",
    "    'reg_lambda' : 1,\n",
    "    'min_split_gain' : 1.3210,\n",
    "    'min_child_weight' : 14.9833,\n",
    "    'metric': 'auc',\n",
    "    'silent': -1,\n",
    "    'verbose': -1,\n",
    "    #scale_pos_weight=11\n",
    "}\n",
    "cls_list = [lgb.LGBMClassifier(**params_lgb) for i in range(11)]\n",
    "for i, idx in enumerate(idx_list):\n",
    "    new_train = train[idx, select_id]\n",
    "    new_y_train = y_train.values[idx]\n",
    "    cls_list[i].fit(new_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "for cls in cls_list:\n",
    "    predict_list.append(cls.predict_proba(test[:, select_id])[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
